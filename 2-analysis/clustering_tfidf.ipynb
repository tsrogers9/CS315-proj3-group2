{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"/users/carolinejung/CS315-proj3-group2/1-data_collection/\" #CHANGE ME!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'hi', 'hadf', 'this', 'is', 'a', 'test', 'hello']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_description(description):\n",
    "    \"\"\"\n",
    "    Helper function, takes video description and splits into words, removes punctuation, emojis and stop words.\n",
    "    \"\"\"\n",
    "    if pd.isna(description):  \n",
    "        return [] \n",
    "    \n",
    "    # remove numbers from the text\n",
    "    description = re.sub(r'\\d+', '', description)\n",
    "\n",
    "    # split the description into words\n",
    "    words = description.split()\n",
    "    \n",
    "    # remove punctuation and emojis, make everything lowercase\n",
    "    cleaned_words = [re.sub(r'[^\\w\\s]', '', word).lower() for word in words]\n",
    "    #return cleaned_words\n",
    "    \n",
    "    # remove stop words and words containing stop hashtags\n",
    "    #cleaned_words = [word for word in cleaned_words if word not in stop_words and not any(stop_tag in word for stop_tag in stop_hashtags)]\n",
    "\n",
    "    # remove empty strings\n",
    "    cleaned_words = [word for word in cleaned_words if word]\n",
    "    return cleaned_words\n",
    "    \n",
    "    # end_string = \"\"\n",
    "    # for word in cleaned_words:\n",
    "    #     if word:\n",
    "    #         end_string += word + \" \"\n",
    "    # return end_string[:-1]\n",
    "\n",
    "clean_description(\"hi hi hadf! this is a test!,   . . hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_string</th>\n",
       "      <th>description_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we all know who the grand puppet master is in ...</td>\n",
       "      <td>[we, all, know, who, the, grand, puppet, maste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if the majority wants to talk about dark money...</td>\n",
       "      <td>[if, the, majority, wants, to, talk, about, da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the party of ‚Äòlaw and order‚Äù ü§îlol, they litera...</td>\n",
       "      <td>[the, party, of, law, and, order, lol, they, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no one should have the right to tell women wha...</td>\n",
       "      <td>[no, one, should, have, the, right, to, tell, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i ran for congress because i was sick of polit...</td>\n",
       "      <td>[i, ran, for, congress, because, i, was, sick,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>we vote within</td>\n",
       "      <td>[we, vote, within]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>as long as you‚Äôre in line by 8pm the polls mus...</td>\n",
       "      <td>[as, long, as, youre, in, line, by, pm, the, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>be like yama and make your voice heard!</td>\n",
       "      <td>[be, like, yama, and, make, your, voice, heard]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>don‚Äôt mail your ballot, drop it off at a dropb...</td>\n",
       "      <td>[dont, mail, your, ballot, drop, it, off, at, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>be sure to fill out your entire ballot! if you...</td>\n",
       "      <td>[be, sure, to, fill, out, your, entire, ballot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>446 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    description_string  \\\n",
       "0    we all know who the grand puppet master is in ...   \n",
       "1    if the majority wants to talk about dark money...   \n",
       "2    the party of ‚Äòlaw and order‚Äù ü§îlol, they litera...   \n",
       "3    no one should have the right to tell women wha...   \n",
       "4    i ran for congress because i was sick of polit...   \n",
       "..                                                 ...   \n",
       "441                                     we vote within   \n",
       "442  as long as you‚Äôre in line by 8pm the polls mus...   \n",
       "443            be like yama and make your voice heard!   \n",
       "444  don‚Äôt mail your ballot, drop it off at a dropb...   \n",
       "445  be sure to fill out your entire ballot! if you...   \n",
       "\n",
       "                                      description_list  \n",
       "0    [we, all, know, who, the, grand, puppet, maste...  \n",
       "1    [if, the, majority, wants, to, talk, about, da...  \n",
       "2    [the, party, of, law, and, order, lol, they, l...  \n",
       "3    [no, one, should, have, the, right, to, tell, ...  \n",
       "4    [i, ran, for, congress, because, i, was, sick,...  \n",
       "..                                                 ...  \n",
       "441                                 [we, vote, within]  \n",
       "442  [as, long, as, youre, in, line, by, pm, the, p...  \n",
       "443    [be, like, yama, and, make, your, voice, heard]  \n",
       "444  [dont, mail, your, ballot, drop, it, off, at, ...  \n",
       "445  [be, sure, to, fill, out, your, entire, ballot...  \n",
       "\n",
       "[446 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_description(gender):\n",
    "    if gender==\"M\":\n",
    "        filepath = \"output_male/\"\n",
    "    elif gender==\"F\":\n",
    "        filepath = \"output_female/\"\n",
    "    else:\n",
    "        print(\"Not a valid input.\")\n",
    "    files = os.listdir(dir_path + filepath)\n",
    "\n",
    "    all_description = []\n",
    "    for file in files:\n",
    "        with open(dir_path + filepath + file, 'r') as f:\n",
    "            account = json.load(f)\n",
    "        f.close()\n",
    "\n",
    "        for video in account:\n",
    "            vid_desc = \"\"\n",
    "            try: \n",
    "                for parts in video[\"description\"]:\n",
    "                    vid_desc += parts.lower()\n",
    "                all_description.append(vid_desc)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    cleaned = [clean_description(desc) for desc in all_description]\n",
    "    data = pd.DataFrame()\n",
    "    data[\"description_string\"] = all_description\n",
    "    data[\"description_list\"] = cleaned\n",
    "    return data\n",
    "\n",
    "df_M = get_description(\"M\")\n",
    "df_F = get_description(\"F\")\n",
    "\n",
    "get_description(\"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all words & convert them into unique word list\n",
    "def unique_words(gender):\n",
    "    df = get_description(gender)\n",
    "    unique = set()\n",
    "    df[\"description_list\"].apply(unique.update)\n",
    "    return list(unique)\n",
    "\n",
    "#sorted(unique_words(\"F\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vector(sentence, voc):\n",
    "    \"\"\"Given a sentence and the vocabulary for the problem,\n",
    "    turn every sentence into a vector.\n",
    "    \"\"\"\n",
    "    cleantext = \"\".join(char for char in sentence if char not in string.punctuation)\n",
    "    words = cleantext.lower().split()\n",
    "    vector = [words.count(w) for w in voc]\n",
    "    return vector\n",
    "\n",
    "def bag_of_words(gender):\n",
    "    sentences = get_description(\"F\")[\"description_string\"]\n",
    "    voc = unique_words(\"F\")\n",
    "    sent2vec = [text2vector(sent, voc) for sent in sentences]\n",
    "    df = pd.DataFrame(sent2vec, \n",
    "                  columns=voc,\n",
    "                  index=[f\"doc_{i+1}\" for i in range(len(sentences))])\n",
    "    return df\n",
    "\n",
    "#bag_of_words(\"F\").to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>013</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>118th</th>\n",
       "      <th>122</th>\n",
       "      <th>12th</th>\n",
       "      <th>14</th>\n",
       "      <th>142</th>\n",
       "      <th>1992</th>\n",
       "      <th>...</th>\n",
       "      <th>ymca</th>\n",
       "      <th>york</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youth</th>\n",
       "      <th>zakaria</th>\n",
       "      <th>zusic</th>\n",
       "      <th>zydeco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.328422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>446 rows √ó 2410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     000  013  100   11  118th  122  12th   14  142  1992  ...  ymca  york  \\\n",
       "0    0.0  0.0  0.0  0.0    0.0  0.0   0.0  0.0  0.0   0.0  ...   0.0   0.0   \n",
       "1    0.0  0.0  0.0  0.0    0.0  0.0   0.0  0.0  0.0   0.0  ...   0.0   0.0   \n",
       "2    0.0  0.0  0.0  0.0    0.0  0.0   0.0  0.0  0.0   0.0  ...   0.0   0.0   \n",
       "3    0.0  0.0  0.0  0.0    0.0  0.0   0.0  0.0  0.0   0.0  ...   0.0   0.0   \n",
       "4    0.0  0.0  0.0  0.0    0.0  0.0   0.0  0.0  0.0   0.0  ...   0.0   0.0   \n",
       "..   ...  ...  ...  ...    ...  ...   ...  ...  ...   ...  ...   ...   ...   \n",
       "441  0.0  0.0  0.0  0.0    0.0  0.0   0.0  0.0  0.0   0.0  ...   0.0   0.0   \n",
       "442  0.0  0.0  0.0  0.0    0.0  0.0   0.0  0.0  0.0   0.0  ...   0.0   0.0   \n",
       "443  0.0  0.0  0.0  0.0    0.0  0.0   0.0  0.0  0.0   0.0  ...   0.0   0.0   \n",
       "444  0.0  0.0  0.0  0.0    0.0  0.0   0.0  0.0  0.0   0.0  ...   0.0   0.0   \n",
       "445  0.0  0.0  0.0  0.0    0.0  0.0   0.0  0.0  0.0   0.0  ...   0.0   0.0   \n",
       "\n",
       "          you  young      your  yourself  youth  zakaria  zusic  zydeco  \n",
       "0    0.000000    0.0  0.000000       0.0    0.0      0.0    0.0     0.0  \n",
       "1    0.000000    0.0  0.000000       0.0    0.0      0.0    0.0     0.0  \n",
       "2    0.000000    0.0  0.000000       0.0    0.0      0.0    0.0     0.0  \n",
       "3    0.000000    0.0  0.000000       0.0    0.0      0.0    0.0     0.0  \n",
       "4    0.000000    0.0  0.000000       0.0    0.0      0.0    0.0     0.0  \n",
       "..        ...    ...       ...       ...    ...      ...    ...     ...  \n",
       "441  0.000000    0.0  0.000000       0.0    0.0      0.0    0.0     0.0  \n",
       "442  0.328422    0.0  0.000000       0.0    0.0      0.0    0.0     0.0  \n",
       "443  0.000000    0.0  0.279634       0.0    0.0      0.0    0.0     0.0  \n",
       "444  0.112038    0.0  0.134646       0.0    0.0      0.0    0.0     0.0  \n",
       "445  0.119080    0.0  0.143109       0.0    0.0      0.0    0.0     0.0  \n",
       "\n",
       "[446 rows x 2410 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualizing\n",
    "tfidfvectorizer = TfidfVectorizer()\n",
    "sentences = get_description(\"F\")[\"description_string\"]\n",
    "X = tfidfvectorizer.fit_transform(sentences)\n",
    "pd.DataFrame(X.toarray(), columns=tfidfvectorizer.get_feature_names_out())\n",
    "# for entire description text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(line):\n",
    "    line = line.lower()\n",
    "    line = re.sub(r\"[{}]\".format(string.punctuation), \" \", line)\n",
    "    return line\n",
    "\n",
    "def create_clusters(gender, k):\n",
    "    sentences = get_description(gender)[\"description_string\"]\n",
    "    tfidf_vectorizer = TfidfVectorizer(preprocessor=preprocessing)\n",
    "    tfidf = tfidf_vectorizer.fit_transform(sentences)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=k).fit(tfidf)\n",
    "    clusters = kmeans.predict(tfidf_vectorizer.transform(sentences))\n",
    "\n",
    "    final_clusters = {}\n",
    "    for i in range(k):\n",
    "        data = sentences\n",
    "        cluster_words = [data[j] for j in range(len(data)) if clusters[j]==i]\n",
    "        final_clusters[f\"cluster{i}\"] = cluster_words\n",
    "    return final_clusters\n",
    "\n",
    "# create_clusters(\"M\", 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate most frequent terms in each cluster? - consider wildcards\n",
    "import operator as op\n",
    "\n",
    "def freq_words(gender, k):\n",
    "    final_clusters = create_clusters(gender, k)\n",
    "    result = []\n",
    "    for cluster in final_clusters:\n",
    "        descriptions = final_clusters[cluster]\n",
    "        all_words = \"\"\n",
    "        for video in descriptions:\n",
    "            for word in clean_description(video):\n",
    "                all_words += word + \" \"\n",
    "        \n",
    "        # TO DO: need to filter out stop words\n",
    "        res = {key: op.countOf(all_words.split(), key) for key in all_words.split()}\n",
    "        final = sorted(res.items(), key=lambda x:x[1], reverse=True)\n",
    "        result.append(final)\n",
    "\n",
    "        # TO DO: store in dictionary that stores which clusters & only get the top ~10 words\n",
    "        \n",
    "    return result\n",
    "\n",
    "# freq_words(\"F\", 6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
