{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorizing videos\n",
    "4/27/2024 \\\n",
    "Author: Tayae Rogers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.23.6-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/tayaerogers/miniconda3/envs/proj2/lib/python3.12/site-packages (from openai) (4.3.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/tayaerogers/miniconda3/envs/proj2/lib/python3.12/site-packages (from openai) (0.27.0)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.7.1-py3-none-any.whl.metadata (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /Users/tayaerogers/miniconda3/envs/proj2/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/tayaerogers/miniconda3/envs/proj2/lib/python3.12/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/tayaerogers/miniconda3/envs/proj2/lib/python3.12/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/tayaerogers/miniconda3/envs/proj2/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in /Users/tayaerogers/miniconda3/envs/proj2/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/tayaerogers/miniconda3/envs/proj2/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/tayaerogers/miniconda3/envs/proj2/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.18.2-cp312-cp312-macosx_10_12_x86_64.whl.metadata (6.5 kB)\n",
      "Downloading openai-1.23.6-py3-none-any.whl (311 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.18.2-cp312-cp312-macosx_10_12_x86_64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: pydantic-core, distro, annotated-types, pydantic, openai\n",
      "Successfully installed annotated-types-0.6.0 distro-1.9.0 openai-1.23.6 pydantic-2.7.1 pydantic-core-2.18.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['API_KEY'] = '' # use own openai key\n",
    "openai.api_key = os.environ['API_KEY']\n",
    "client = openai.OpenAI(\n",
    "    api_key=openai.api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(vid_descr_list):\n",
    "    \"\"\"\n",
    "    Input: string - a video description\n",
    "    Output: string - category of that video\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_format={\"type\":\"json_object\"},\n",
    "        messages=[\n",
    "            {\"role\":\"system\", \"content\":\"You are a helpful assistant designed to output JSON.\"},\n",
    "            {\"role\":\"user\", \"content\":f\"\"\"The input is a list of string video descriptions. For each video description\n",
    "            in the list, identify its topic as one or two of the following topics in this list: \"civil rights,\" \"culture,\" \"energy and environment,\"\n",
    "            \"health, education, and labor,\" \"immigration and international affairs,\" \"housing and social welfare,\" \"defense, law, and crime,\"\n",
    "            \"economy, commerce, and transportation,\" and/or \"other.\" For example, if the input list is [\"global warming is causing\n",
    "            more extreme weather events\", \"we must adopt unviersal health care\"], the output should be [\"energy and environment,\"\n",
    "            \"health, education, and labor\"]\n",
    "            The input list is {vid_descr_list}\"\"\"}\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tayaerogers/Documents/MEDSL/GitHub/CS315-proj3-group2/2-analysisF_all_vid_descriptions_2024_04_27.csv'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd() + 'F_all_vid_descriptions_2024_04_27.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_descriptions = pd.read_csv(os.getcwd() + '/F_all_vid_descriptions_2024_04_27.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we all know who the grand puppet master is in this impeachment. the long arm (but small hands) of donald trump and his fingerprints are all over this hearing and gop shut down.',\n",
       " 'if the majority wants to talk about dark money and activist courts, i am so here for it.so, let’s talk about how right wing organizations bankroll judicial decisions to undermine our fundamental rights and judicial system.',\n",
       " 'the party of ‘law and order” 🤔lol, they literally have a history of interfering in criminal investigations for political gain.today’s oversight hearing is purely a political stunt. period.',\n",
       " \"no one should have the right to tell women what we can and can't do with our bodies—including the supreme court.right now scotus is considering whether or not women should have access to life saving medications like mifepristone. the law must follow the science and protect our rights, not a political agenda.\",\n",
       " 'i ran for congress because i was sick of politicians telling communities they would help them, only to turn around and use them for political theater.we’ve known for years of the behavioral health and public safety crises ravaging our tribes and pueblos, and it’s time we actually listen to tribal leaders and let them lead.',\n",
       " 'it’s official! my bipartisan veterans and outdoor accessibility bill passed the house last night as part of the explore act! it is now on its way to the senate and hopefully president biden’s desk! 🤞🏻',\n",
       " 'as a proud graduate of albuquerque public schools—we know our graduates go on to do amazing things. take city councilor nichole rogers, who graduated from cibola just like me! (go cougars! 🐾) or aps superintendent gabriella blakey, who graduated from highland! so excited to see what this year’s graduates do next!',\n",
       " 'healthcare is a human right. period. we must do everything we can to ensure our communities can access care.',\n",
       " 'every single living being deserves fresh air, clean water, and a healthy planet to live on.that’s why i brought some of new mexico’s brightest minds together for a roundtable to talk how we can make that hope a reality. i’m grateful every day to work with so many amazing groups that are leading the way for a just transition into climate resiliency.',\n",
       " \"our communities deserve every opportunity to thrive—which means access to healthcare, mental and behavioral health programs, and addiction services. unfortunately, so many in new mexico are struggling to access that care. that's why i was deeply grateful to join the congressional hispanic caucus, rep. teresa leger fernández, and u.s. department of health and human services secretary becerra today as we heard from you on how we can help get better care to our communities.\"]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first10_female = vid_descriptions['description_string'].to_list()[:10]\n",
    "first10_female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "first10_female_gpt_output = get_category(first10_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'choices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfirst10_female_gpt_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'choices'"
     ]
    }
   ],
   "source": [
    "first10_female_gpt_output.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
